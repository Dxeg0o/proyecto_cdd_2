{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from plotnine import *\n",
        "from statistics import LinearRegression\n",
        "from scipy.stats import expon, chi2, chi2_contingency, chisquare\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import make_scorer, accuracy_score, recall_score, precision_score, f1_score, mean_squared_error, r2_score\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('Base de Datos.csv', delimiter=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['NOM_REG_RBD_A'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_regiones = df[(df['NOM_REG_RBD_A'] == 'RM') | (df['NOM_REG_RBD_A'] == 'NUBLE')]\n",
        "df_regiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3.1 Pregunta 0 (descripción de variables)**\n",
        "\n",
        "Con el objetivo de familiarizarse y entender mejor la base de datos, se requiere realizar un analisis de esta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Generar un grafico por cada una de las variables. El grafico debe tener un tıtulo descriptivo y debe mostrar\n",
        "informacion clara de la variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#1\n",
        "(ggplot(df_regiones)+\n",
        " aes(x=\"AGNO\",y=\"..count..\")+\n",
        " geom_bar(fill=\"blue\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(ggplot(df_regiones)+\n",
        " aes(x=\"RBD\")+\n",
        " geom_bar(color=\"red\",fill=\"red\")+\n",
        " theme_linedraw()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#3\n",
        "(ggplot(df_regiones)+\n",
        " aes(x=\"DGV_RBD\",y=\"..count..\")+\n",
        " geom_bar(fill=\"blue\")+\n",
        " theme(axis_text_x=element_text(angle=90,hjust=1)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(ggplot(df_regiones)+\n",
        " aes(x=\"NOM_RBD\")+\n",
        " geom_bar(color=\"red\",fill=\"red\")+\n",
        " theme_linedraw()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Se debe indicar por cada una de las variables su tipo (cuantitativa o cualitativa) justificando su decision. Se\n",
        "debe recordar que el tipo de variable depende de su naturaleza, no del formato en el que se encuentre en la\n",
        "base de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**LAS VARIABLES SON DE TIPO:**\n",
        "\n",
        "AGNO (Año de la información): Cuantitativa\n",
        "\n",
        "RBD(Rol Base de Datos del establecimiento): Cuantitativa\n",
        "\n",
        "DGV_RBD(Dígito verificador del RBD): Cualitativa\n",
        "\n",
        "NOM_RBD(Nombre del establecimiento): Cualitativa\n",
        "\n",
        "COD_REG_RBD(Código de región en que se ubica el establecimiento): Cualitativa\n",
        "\n",
        "NOM_REG_RBD_A(Nombre de la Región abreviado): Cualitativa\n",
        "\n",
        "COD_PRO_RBD(Código oficial de provincia en que se ubica el establecimiento): Cualitativa\n",
        "\n",
        "COD_COM_RBD(Código oficial de comuna en que se ubica el establecimiento): Cualitativa\n",
        "\n",
        "NOM_COM_RBD(Nombre de la comuna): Cualitativa\n",
        "\n",
        "COD_DEPROV_RBD(Código del Departamento Provincial en que se ubica el establecimiento): Cualitativa\n",
        "\n",
        "NOM_DEPROV_RBD(Nombre del Departamento Provincial en que se ubica el establecimiento): Cualitativa\n",
        "\n",
        "COD_DEPE(Dependencia administrativa del Establecimiento: 1: Corporación Municipal 2: Municipal DAEM 3: Particular Subvencionado 4: Particular Pagado 5: Corporación de Administración Delegada (DL 3166) 6: Servicio Local de Educación 7: JUNJI ): Cualitativa\n",
        "\n",
        "COD_DEPE2(Código de Dependencia del Establecimiento (agrupado): 1: Municipal 2: Particular Subvencionado 3: Particular Pagado (o no subvencionado) 4: Corporación de Administración Delegada (DL 3166) 5: Servicio Local de Educación 6: JUNJI ): Cualitativa\n",
        "\n",
        "RURAL_RBD(Área geográfica en que se ubica el establecimiento 0: Urbana 1: Rural ): Cualitativa\n",
        "\n",
        "ESTADO_ESTAB(Estado de funcionamiento del establecimiento 1: Funcionando 2: En Receso 3: Cerrado 4: Autorizado sin Matrícula ): Cualitativa\n",
        "\n",
        "DC_A(Total de Docentes de aula): Cuantitativa\n",
        "\n",
        "HH_A(Horas de Contrato de los Docentes de aula): Cuantitativa\n",
        "\n",
        "DC_UTP(Total de Docentes planta Unidad Técnico-Pedagógica): Cuantitativa\n",
        "\n",
        "HH_UTP(Horas de Contrato de los Docentes planta Unidad Técnico-Pedagógica): Cuantitativa\n",
        "\n",
        "DC_PDIR(Total de Docentes Planta Directiva): Cuantitativa\n",
        "\n",
        "HH_PDIR(Horas de Contrato de los docentes de la Planta Directiva): Cuantitativa\n",
        "\n",
        "DC_DIR(Número total de Directores(as)): Cuantitativa\n",
        "\n",
        "HH_DIR(Horas de Contrato de los Directores(as)): Cuantitativa\n",
        "\n",
        "DC_OES(Total de Docentes que ejercen otra función en el establecimiento): Cuantitativa\n",
        "\n",
        "HH_OES(Horas de Contrato de los docentes que ejercen otra función en el establecimiento): Cuantitativa\n",
        "\n",
        "DC_OF(Total de Docentes que ejercen otra función fuera del establecimiento): Cuantitativa\n",
        "\n",
        "HH_OF(Horas de Contrato de los docentes que ejercen otra función fuera del establecimiento): Cuantitativa\n",
        "\n",
        "DC_JUTP(Total de Jefes de Unidad TécnicoPedagógica): Cuantitativa\n",
        "\n",
        "HH_JUTP(Horas de Contrato de los Jefes de Unidad Técnico-Pedagógica): Cuantitativa\n",
        "\n",
        "DC_IG(Total de Inspectores Generales): Cuantitativa\n",
        "\n",
        "HH_IG(Horas de Contrato de los Inspectores Generales): Cuantitativa\n",
        "\n",
        "DC_OR(Total de Orientadores): Cuantitativa\n",
        "\n",
        "HH_OR(Horas de Contrato de los Orientadores): Cuantitativa\n",
        "\n",
        "DC_DIR_SOST(Total de docentes que cumplen funciones Directivas con el sostenedor): Cuantitativa\n",
        "\n",
        "HH_DIR_SOST(Horas Directivas con el sostenedor): Cuantitativa\n",
        "\n",
        "DC_TP_SOST(Total de docentes que cumplen funciones Técnico-pedagógicas con el sostenedor): Cuantitativa\n",
        "\n",
        "HH_TP_SOST(Horas Técnico-pedagógicas con el sostenedor): Cuantitativa\n",
        "\n",
        "DC_SUP_SOST(Total de docentes que cumplen funciones de Supervisión con el sostenedor): Cuantitativa\n",
        "\n",
        "HH_SUP_SOST(Horas de Supervisión con el sostenedor): Cuantitativa\n",
        "\n",
        "DC_SUBDIR(Número total de Sub Directores(as)): Cuantitativa\n",
        "\n",
        "HH_SUBDIR(Horas de Contrato de los SubDirectores(as)): Cuantitativa\n",
        "\n",
        "DC_PROF_ENC(Número total de Profesores(as) Encargados): Cuantitativa\n",
        "\n",
        "HH_PROF_ENC(Horas de Contrato de los Profesores(as) Encargados): Cuantitativa\n",
        "\n",
        "DC_EDUC_TRAD(Total de Docentes que ejercen como Educadores Tradicionales): Cuantitativa\n",
        "\n",
        "HH_EDUC_TRAD(Horas de Contrato de los docentes que ejercen como Educadores Tradicionales): Cuantitativa\n",
        "\n",
        "DC_TOT(Total de Docentes en el establecimiento): Cuantitativa\n",
        "\n",
        "HH_TOT(Total de Horas de contrato en el establecimiento): Cuantitativa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3.2 Pregunta 1 (test de independencia)**\n",
        "\n",
        "Los docentes UTP (Unidad Tecnico Pedagogica) en Chile son profesionales de la educacion encargados de la coordinacion pedagogica y tecnica en las instituciones educativas. Se dedican a la planificacion, evaluacion y seguimiento del rendimiento academico de los estudiantes, ofrecen apoyo y orientacion a otros docentes, participan en el desarrollo profesional y gestionan aspectos curriculares. Tambien mantienen comunicacion con los padres para informarles sobre el progreso de los estudiantes, desempeñando un papel fundamental en la mejora de la calidad educativa en\n",
        "el paıs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Obtenga un grafico apropiado que le permita estudiar la distribucion del numero de docentes pertenecientes a\n",
        "la planta UTP en los establecimientos educacionales de sus regiones. Discuta las caracterısticas mas relevantes\n",
        "presentes en sus graficos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#1\n",
        "(ggplot(df_regiones)+\n",
        " aes(x=\"DC_UTP\")+\n",
        " geom_bar(color=\"red\",fill=\"red\")+\n",
        " theme_linedraw()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se evidencia la presencia de muchos establecimientos con 0 docentes pertenecientes a la planta UTP en los establecimientos educacionales. TAL VEZ FALTA MAs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Al Ministerio de Educacion le preocupa que existan diferencias en el numero de docentes UTP entre los distintos tipos de establecimientos (municipales, particulares subvencionados y particulares pagados). Implemente un test de independencia chi-cuadrado que le permita concluir si existe dependencia entre el tipo de establecimiento: (solo considere municipales, particulares subvencionados y particulares pagados) y el numero\n",
        "de docentes UTP. En particular:\n",
        "\n",
        "• Reporte la tabla de frecuencias observadas y esperadas.\n",
        "\n",
        "• Reporte el p-valor obtenido y concluya con un valor α = 0.05. Interprete sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtrar los tipos de establecimientos de interés \n",
        "tipos_establecimiento_interes = [1, 2, 3]\n",
        "df_filtrado = df_regiones[df_regiones['COD_DEPE2'].isin(tipos_establecimiento_interes)]\n",
        "\n",
        "# Calcular la tabla de contingencia\n",
        "tabla_contingencia = pd.crosstab(df_filtrado['COD_DEPE2'], df_filtrado['DC_UTP'])\n",
        "\n",
        "# Realizar el test chi-cuadrado de independencia\n",
        "chi2, p_valor, tabla_esperada, _ = chi2_contingency(tabla_contingencia, correction=False)\n",
        "\n",
        "# Mostrar la tabla de frecuencias observadas y esperadas\n",
        "print(\"Tabla de Frecuencias Observadas:\")\n",
        "print(tabla_contingencia)\n",
        "print(\"\\nTabla de Frecuencias Esperadas:\")\n",
        "print(pd.DataFrame(tabla_esperada, index=tabla_contingencia.index, columns=tabla_contingencia.columns))\n",
        "print(\"\\nP-valor obtenido:\", p_valor)\n",
        "\n",
        "# Interpretar los resultados con α = 0.05\n",
        "alpha = 0.05\n",
        "if p_valor < alpha:\n",
        "    print(\"\\nEl p-valor es menor que alpha (0.05), se rechaza la hipótesis nula.\")\n",
        "    print(\"Hay evidencia suficiente para afirmar una asociación significativa entre el tipo de establecimiento y el número de docentes UTP.\")\n",
        "else:\n",
        "    print(\"\\nEl p-valor es mayor que alpha (0.05), no se rechaza la hipótesis nula.\")\n",
        "    print(\"No hay suficiente evidencia para afirmar una asociación significativa entre las variables.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Obtenga un grafico apropiado para mostrar la distribucion del numero de docentes de planta UTP por establecimiento. Finalmente, muestre como esa distribucion cambia (o no) para los distintos establecimientos: Municipales, particulares suvencionados y particulares pagados. Incluya una breve discusion sobre si lo que observa en sus graficos concuerda con lo obtenido en la implementacion del test anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtrar los datos por tipo de establecimiento\n",
        "municipales = df_regiones[df_regiones['COD_DEPE2'] == 1]['DC_UTP']\n",
        "subvencionados = df_regiones[df_regiones['COD_DEPE2'] == 2]['DC_UTP']\n",
        "pagados = df_regiones[df_regiones['COD_DEPE2'] == 3]['DC_UTP']\n",
        "\n",
        "# Gráfico de densidad suavizado (KDE) para comparar las distribuciones\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.kdeplot(municipales, fill=True, label='Municipales')\n",
        "sns.kdeplot(subvencionados, fill=True, label='Subvencionados')\n",
        "sns.kdeplot(pagados, fill=True, label='Pagados')\n",
        "plt.title('Distribución de Docentes UTP por Tipo de Establecimiento')\n",
        "plt.xlabel('Número de Docentes UTP')\n",
        "plt.ylabel('Densidad de Probabilidad')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar estilo de seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Crear subgráficos para cada tipo de establecimiento\n",
        "fig, axs = plt.subplots(3, 1, figsize=(8, 12), sharex=True, sharey=True)\n",
        "\n",
        "# Gráfico de densidad para municipales\n",
        "sns.kdeplot(municipales, ax=axs[0], fill=True, label='Municipales')\n",
        "axs[0].set_title('Distribución de Docentes UTP - Municipales')\n",
        "axs[0].set_ylabel('Densidad de Probabilidad')\n",
        "axs[0].legend()\n",
        "\n",
        "# Gráfico de densidad para subvencionados\n",
        "sns.kdeplot(subvencionados, ax=axs[1], fill=True, label='Subvencionados')\n",
        "axs[1].set_title('Distribución de Docentes UTP - Subvencionados')\n",
        "axs[1].set_ylabel('Densidad de Probabilidad')\n",
        "axs[1].legend()\n",
        "\n",
        "# Gráfico de densidad para pagados\n",
        "sns.kdeplot(pagados, ax=axs[2], fill=True, label='Pagados')\n",
        "axs[2].set_title('Distribución de Docentes UTP - Pagados')\n",
        "axs[2].set_xlabel('Número de Docentes UTP')\n",
        "axs[2].set_ylabel('Densidad de Probabilidad')\n",
        "axs[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NO ESTOY SEGUROOOO\n",
        "Gracias a los graficos podemos ver que no hay relacion segun yo no se AYUDAAAAAA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3.3 Pregunta 2 (test de bondad de ajuste)**\n",
        "\n",
        "En Chile, las “Horas de Contrato” (variable HH_A) para los docentes de aula se refieren a la cantidad de horas que los\n",
        "profesores est´an contratados para trabajar en una institucion educativa durante un perıodo especıfico, generalmente\n",
        "un año escolar. La cantidad de horas de contrato puede variar segun el nivel educativo y el tipo de establecimiento\n",
        "educacional.\n",
        "En el contexto de un estudio educativo, se plantea la hipotesis de que las Horas de Contrato de los Docentes\n",
        "de Aula siguen una distribucion exponencial. Para investigar esta afirmacion, sigua los siguientes pasos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Analisis Visual: Genere un histograma de densidad para la variable en cuestion y añada en este grafico la funcion de densidad asociada a la distribucion exponencial. Disculta sobre la factibilidad de la hipotesis planteada en el estudio utilizando el histograma generado.\n",
        "\n",
        "**Hint**: Recuerde que la densidad de la distribucion exponencial esta dada por:\n",
        "f(x) = λ exp{−λx},\n",
        "y que para la construccion de su grafico es razonable estimar el parametro λ usando X¯ −1 donde X¯ representa el promedio de HH_A."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Supongamos que ya tienes un DataFrame llamado df con la columna \"HH_A\" que contiene las horas de contrato\n",
        "\n",
        "# Calcular el promedio de HH_A\n",
        "promedio_horas = df_regiones[\"HH_A\"].mean()\n",
        "\n",
        "# Crear un histograma de las horas de contrato\n",
        "plt.hist(df[\"HH_A\"], bins=20, density=True, color=\"red\", edgecolor=\"black\", alpha=0.7, label=\"Histograma\")\n",
        "\n",
        "# Crear la función de densidad exponencial\n",
        "x = np.linspace(0, max(df[\"HH_A\"]), 100)\n",
        "lambda_parametro = 1 / promedio_horas\n",
        "densidad_exponencial = expon.pdf(x, scale=1/lambda_parametro)\n",
        "\n",
        "# Agregar la función de densidad al gráfico\n",
        "plt.plot(x, densidad_exponencial, color=\"blue\", label=\"Densidad Exponencial\")\n",
        "\n",
        "# Configurar el gráfico\n",
        "plt.title(\"Horas de Contrato\")\n",
        "plt.xlabel(\"Horas\")\n",
        "plt.ylabel(\"Densidad\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#falta discutir sobre la factibilidad de la hipotesis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Evaluacion Estadıstica: Implemente un test de hipotesis de bondad de ajuste con un nivel de significancia de α = 0.05 que le permita concluir sobre la hipotesis planteada en el estudio. Recuerde que el test de bondad\n",
        "de ajuste le permite analizar si los datos se comportan como una distribucion en especıfico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener el promedio de HH_A\n",
        "promedio_horas = df_regiones[\"HH_A\"].mean()\n",
        "\n",
        "# Crear la función de densidad exponencial\n",
        "x = np.linspace(0, max(df[\"HH_A\"]), 20)  # Ajustar la cantidad de puntos a la cantidad de bins\n",
        "lambda_parametro = 1 / promedio_horas\n",
        "densidad_exponencial = stats.expon.pdf(x, scale=1/lambda_parametro)\n",
        "\n",
        "# Ajustar la distribución exponencial al histograma\n",
        "freq, _ = np.histogram(df[\"HH_A\"], bins=20, density=True)\n",
        "expected = densidad_exponencial * np.sum(freq)\n",
        "observed = freq\n",
        "\n",
        "# Calcular el estadístico chi-cuadrado y el p-valor\n",
        "chi_squared_stat = np.sum((observed - expected) ** 2 / expected)\n",
        "p_value = 1 - stats.chi2.cdf(chi_squared_stat, df=len(observed) - 1)\n",
        "\n",
        "# Mostrar el p-valor\n",
        "print(\"El p-valor es:\", p_value)\n",
        "\n",
        "# Establecer el nivel de significancia\n",
        "alpha = 0.05\n",
        "\n",
        "# Comprobar la significancia estadística\n",
        "if p_value < alpha:\n",
        "    print(\"Se rechaza la hipótesis nula: los datos no siguen una distribución exponencial.\")\n",
        "else:\n",
        "    print(\"No se puede rechazar la hipótesis nula: los datos podrían seguir una distribución exponencial.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3.4 Pregunta 3 (regresion lineal simple y multiple)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Regresion lineal simple: Implemente un modelo de regresion lineal simple que le permita modelar las\n",
        "Horas de Contrato de los Docentes de Aula (variable HH_A) en funcion del Total de Docentes de aula (variable\n",
        "DC_A).\n",
        "Los pasos que debera realizar para dar respuesta a esta pregunta son:\n",
        "\n",
        "(a) Obtenga la correlacion entre las variables involucradas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correlacion = df_regiones['DC_A'].corr(df['HH_A'])\n",
        "print(f\"La correlación entre las variables de las Horas de Contrato de los Docentes de Aula y Total de Docentes de aula es: {correlacion}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(b) Visualize la relacion entre las variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.scatterplot(df_regiones, x=\"DC_A\", y=\"HH_A\")\n",
        "plt.xlabel(\"Horas de contrato de docentes de aula\")\n",
        "plt.ylabel(\"Total de Docentes de aula\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(c) Separe los datos en conjuntos de datos de entrenamiento y testeo. Luego ajuste el modelo de regresion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Utilizando solo las columnas 'DC_A' y 'HH_A' para el entrenamiento\n",
        "X = df_regiones[['HH_A']]\n",
        "y = df_regiones['DC_A']\n",
        "\n",
        "# Dividiendo los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creando el modelo de regresión lineal\n",
        "modelo = LinearRegression()\n",
        "\n",
        "# Entrenando el modelo\n",
        "modelo.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(d) Muestre en una tabla los coeficientes obtenidos (Intercepto y pendiente). Interprete sus resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "intercepto= modelo.intercept_\n",
        "pendiente= modelo.coef_\n",
        "\n",
        "resultados = pd.DataFrame({\n",
        "    'Coeficiente': ['Intercepto', 'Pendiente'],\n",
        "    'Valor': [intercepto, pendiente]\n",
        "})\n",
        "\n",
        "resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos darno cuenta que la función modelada va decreciendo con un pendiente de -16,35 y corta el eje Y en el 37,92"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(e) Visualize el modelo de regresion utilizando los coeficientes encontrados en el paso anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(X_train, y_train, color='blue', label='Datos Observados')\n",
        "plt.plot(X_train, modelo.predict(X_train), color='red', label='Regresión Lineal')\n",
        "plt.xlabel('Total de Docentes de Aula')\n",
        "plt.ylabel('Horas de Contrato de los Docentes de Aula')\n",
        "plt.title('Regresión Lineal: Horas de Contrato vs Total de Docentes')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(f) Obtenga y comente el coeficiente de determinacion obtenido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = modelo.predict(X_train)\n",
        "\n",
        "# Calcular el coeficiente de determinación\n",
        "r2 = r2_score(y_train, y_pred)\n",
        "\n",
        "print(f\"Coeficiente de determinación (R^2): {r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Que nos haya dado un valor de 0.98 sugiere que el modelo en cuestión explica el 98% de la variabilidad en la variable dependiente que es: Horas de Contrato de los Docentes de Aula, a partir de la variable independiente: Total de Docentes de Aula. Que hayamos obtenido un R^2 cercan a 1, indica que el modelo podra predecir con buena exactitud las Horas de Contrato de los Docentes de Aula en relación con el Total de Docentes de Aula."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(g) Evalue su modelo utilizando los datos del set de testeo. \n",
        "Para esto, calcule el MSE y RMSE predictivos\n",
        "(error cuadratico medio y raız del error cuadratico medio). ¿Que significan los valores obtenidos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Haciendo predicciones en el conjunto de prueba\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "# Calculando las métricas de rendimiento\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared score: {r2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#FALTA INTERPRETAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Regresion lineal multiple: En esta pregunta se le pide que implemente un modelo de regresion lineal\n",
        "multiple para modelar las Horas de Contrato de los Docentes de Aula (variable HH_A) en funcion del Total\n",
        "de Docentes de aula (variable DC_A) y de tres variables mas que usted debe escoger. Para escoger\n",
        "estas variables usted debe usar criterios claros y objetivos (por ejemplo, puede elegir las variables que mas se\n",
        "correlacionan con la variable dependiente).\n",
        "Utilizando la misma separacion de entrenamiento y testing realizada en el ıtem anterior responda: ¿Que\n",
        "impacto tienen las variable adicionales en el rendimiento de su modelo? Comente en funcion de los nuevas\n",
        "metricas obtenidas (error cuadratico medio y R2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# usasmos esto para saver seber cuales son las variables que mas se correlacionan \n",
        "df_numeric = df_regiones.select_dtypes(include=[np.number])\n",
        "correlation_matrix = df_numeric.corr()\n",
        "print(correlation_matrix['HH_A'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Selecciona tus variables independientes\n",
        "X = df_regiones[['DC_A', 'HH_TOT', 'DC_TOT', 'HH_IG']]\n",
        "# Selecciona tu variable dependiente\n",
        "y = df_regiones['HH_A']\n",
        "# Divide tus datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Crea una instancia de la clase LinearRegression\n",
        "regressor = LinearRegression()\n",
        "# Entrena el modelo\n",
        "regressor.fit(X_train, y_train)\n",
        "# Haz predicciones en el conjunto de prueba\n",
        "y_pred = regressor.predict(X_test)\n",
        "# Calcula el error cuadrático medio y el coeficiente de determinación R^2\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'Error cuadrático medio: {mse}')\n",
        "print(f'Coeficiente de determinación R^2: {r2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3.5 Pregunta 4 (clasificacion y validacion)**\n",
        "\n",
        "En esta pregunta se le pide que implemente dos modelos de clasificacion: Support Vector Machine y Regresion\n",
        "Logıstica. El objetivo es generar un modelo que prediga si la variable Horas de Contrato de los Docentes de Aula\n",
        "(variable HH A) es mayor a 160 horas. Los modelos deben ser implementados usando validacion simple y K-Fold\n",
        "Cross validation. Los pasos para responder la pregunta son:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Genere una nueva variable a partir de Horas de Contrato de los Docentes de Aula (variable HH A) que tome\n",
        "el valor de 1 si supera las 160 horas, y tenga valor 0 si es menor o igual a este valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_regiones.loc[df[\"HH_A\"] <= 160, \"HH_A_BINARIO\"] = 0\n",
        "df_regiones.loc[df[\"HH_A\"] > 160, \"HH_A_BINARIO\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_regiones[\"HH_A_BINARIO\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Seleccione la variable Total de Docentes de aula (variable DC A) y las tres mejores variables. Para escoger\n",
        "estas variables usted debe justificar usando criterios claros y objetivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_cuantitativas = df_regiones.select_dtypes(include=['int', 'float'])\n",
        "corr_matrix = variables_cuantitativas.corr()\n",
        "corr_matrix['HH_A_BINARIO'].abs().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seleccionamos las variables HH_DIR, DC_DIR Y DC_TOT, al ser las que tienen mayor correlación con la variable de interes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Genere un nuevo dataframe que contenga: la variable Total de Docentes de aula, las 3 variables que escogio\n",
        "y la nueva variable generada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_4=df_regiones[[\"HH_A_BINARIO\",\"HH_DIR\",\"DC_DIR\",\"DC_TOT\",\"DC_A\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Con el data frame obtenido, aplique el modelo SVM utilizando la tecnica de validacion simple. Obtenga los\n",
        "valores de las metricas: accuracy, recall, precision y f1 score. Explique como interpretarıa los resultados de\n",
        "estas metricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df_4.drop(\"HH_A_BINARIO\", axis=1)  \n",
        "y = df_4[\"HH_A_BINARIO\"] \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy:{accuracy}\\nRecall:{recall}\\nPrecision:{precision}\\nF1 Score:{f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El valor de Accuracy dió aproximadamente 0.9674, lo que significa que un 96% de las predicciones realizadas son correctas\n",
        "El valor de Recall dió aproximadamente 0.96133, lo que indica que se idetificó correctamente el 96% de los docentes que tiene contratos mayor a 160 horas y el 4% de las veces no se identificó que los docentes tenían contratos mayor a 160 horas. \n",
        "El valor de la precision dió aproximadamente 0.9802, lo que indica que se identificó correctamente el 98% de los casos en los que la variable era positiva, es decir, de 100 predicciones positivas (horas de contrato mayor a 160) acertó 98 veces y erró en 2 ocasiones.\n",
        "El valor de F1 dió aproximadamente 0.9707, esta metrica indica que hay un buen balance entre recall y precision, indicando un buen funcionamiento en la validación simple del modelo y de la división de los datos realizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Con el data frame obtenido, aplique el modelo Regresion Logıstica utilizando la tecnica de validacion simple.\n",
        "Obtenga los valores de las metricas: accuracy, recall, precision y f1 score. Explique como interpretarıa los\n",
        "resultados de estas metricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df_4.drop(\"HH_A_BINARIO\", axis=1)\n",
        "y = df_4[\"HH_A_BINARIO\"] \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy:{accuracy}\\nRecall:{recall}\\nPrecision:{precision}\\nF1 Score:{f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El valor de Accuracy dió aproximadamente 0.9703, lo que significa que un 97% de las predicciones realizadas son correctas\n",
        "El valor de Recall dió aproximadamente 0.9666, lo que indica que se idetificó correctamente el 96% de los docentes que tiene contratos mayor a 160 horas y el 4% de las veces no se identificó que los docentes tenían contratos mayor a 160 horas. \n",
        "El valor de la precision dió aproximadamente 0.9803, lo que indica que se identificó correctamente el 98% de los casos en los que la variable era positiva, es decir, de 100 predicciones positivas (horas de contrato mayor a 160) acertó 98 veces y erró en 2 ocasiones.\n",
        "El valor de F1 dió aproximadamente 0.9734, esta metrica indica que hay un buen balance entre recall y precision, indicando un buen funcionamiento en la validación simple del modelo y de la división de los datos realizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Mencione la principal deficiencia de aplicar validacion simple aplicada para este caso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La principal deficiencia de aplicar la técnica de validación simple es que el modelo aplicado depende en gran medida de la forma en que se realizó la división entre los datos de prueba y de los de predicción.\n",
        "Y si justo la división realizada resulta no ser representativa del conjunto de datos, los resultados del modelo pueden ser sesgados en base a dicha división, resultando en una predicción que no representa el resto de datos\n",
        "Teniendo lo anterior en cuenta la principal deficiencia de la validación simple podría ser la dependencia a como se hizo la división de los datos del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. Con el data frame obtenido, aplique el modelo SVM utilizando la tecnica de validacion cruzada. Obtenga\n",
        "los valores de las metricas: accuracy, recall, precision y f1 score. Determine si su modelo se encuentra sobre\n",
        "entrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df_4.drop(\"HH_A_BINARIO\", axis=1)  \n",
        "y = df_4[\"HH_A_BINARIO\"] \n",
        "\n",
        "svm_model = SVC()\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'recall': make_scorer(recall_score),\n",
        "    'precision': make_scorer(precision_score),\n",
        "    'f1': make_scorer(f1_score)\n",
        "}\n",
        "\n",
        "cv_results = cross_validate(svm_model, X, y, cv=5, scoring=scoring)\n",
        "\n",
        "print(f\"Accuracy: {cv_results['test_accuracy'].mean()}\")\n",
        "print(f\"Recall: {cv_results['test_recall'].mean()}\")\n",
        "print(f\"Precision: {cv_results['test_precision'].mean()}\")\n",
        "print(f\"F1 Score: {cv_results['test_f1'].mean()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las metricas son las siguientes: Accuracy: 0.9628, Recall: 0.9557, Precision: 0.9762 y F1 Score: 0.9652. Las cuales nos indican que hay unas buenas medidas y que el modelo en general si está bien entrenado, debido a que generaliza bien la mayoría de los datos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8. Con el data frame obtenido, aplique el modelo Regresion Logıstica utilizando la tecnica de validacion cruzada.\n",
        "Obtenga los valores de las metricas: accuracy, recall, precision y f1 score. Determine si su modelo se encuentra\n",
        "sobre entrenado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df_4.drop(\"HH_A_BINARIO\", axis=1)  \n",
        "y = df_4[\"HH_A_BINARIO\"] \n",
        "\n",
        "logistic_model = LogisticRegression()\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'recall': make_scorer(recall_score),\n",
        "    'precision': make_scorer(precision_score),\n",
        "    'f1': make_scorer(f1_score)\n",
        "}\n",
        "\n",
        "cv_results = cross_validate(logistic_model, X, y, cv=5, scoring=scoring)\n",
        "\n",
        "print(f\"Accuracy: {cv_results['test_accuracy'].mean()}\")\n",
        "print(f\"Recall: {cv_results['test_recall'].mean()}\")\n",
        "print(f\"Precision: {cv_results['test_precision'].mean()}\")\n",
        "print(f\"F1 Score: {cv_results['test_f1'].mean()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las metricas son las siguientes:Accuracy: 0.9675, Recall: 0.9622, Precision: 0.97841 y F1 Score: 0.9699, Las cuales nos indican que hay unas buenas medidas y que el modelo en general si está bien entrenado, debido a que generaliza bien la mayoría de los datos. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
